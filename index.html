<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>EcoSort</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <style>
    :root {
      --green-main: #166534;       /* deep calm green */
      --green-soft: #15803d;
      --gray-bg:   #f5f5f5;       /* light gray cards */
      --gray-border: #e5e5e5;
      --text-muted: #4b5563;
      --max-width: 900px;
    }

    * {
      box-sizing: border-box;
      scroll-behavior: smooth;
    }

    body {
      margin: 0;
      padding: 0;
      font-family: -apple-system, BlinkMacSystemFont, "SF Pro Text",
                   system-ui, -system-ui, "Segoe UI", sans-serif;
      background: #ffffff;
      color: var(--green-main);
    }

    a {
      color: inherit;
      text-decoration: none;
    }

    /* Top nav – minimal, low visual weight */
    header {
      position: fixed;
      top: 0;
      left: 0;
      right: 0;
      height: 56px;
      background: rgba(255, 255, 255, 0.9);
      backdrop-filter: blur(10px);
      border-bottom: 1px solid rgba(229, 231, 235, 0.8);
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 0 24px;
      z-index: 20;
    }

    .logo {
      font-weight: 600;
      letter-spacing: 0.04em;
      font-size: 14px;
      text-transform: none;
    }

    nav {
      display: flex;
      gap: 18px;
      font-size: 13px;
    }

    nav a {
      padding: 4px 8px;
      border-radius: 999px;
      color: var(--text-muted);
    }

    nav a:hover {
      background: #f3f4f6;
      color: var(--green-main);
    }

    /* Layout for sections */
    main {
      padding-top: 72px; /* space for fixed header */
    }

    section {
      min-height: 70vh;
      padding: 40px 20px 60px;
      display: flex;
      justify-content: center;
    }

    .section-inner {
      width: 100%;
      max-width: var(--max-width);
    }

    .section-label {
      font-size: 11px;
      letter-spacing: 0.16em;
      text-transform: uppercase;
      color: var(--text-muted);
      margin-bottom: 8px;
    }

    h1, h2 {
      margin: 0 0 16px;
      font-weight: 600;
      letter-spacing: 0.02em;
    }

    h1 {
      font-size: clamp(32px, 5vw, 48px);
    }

    h2 {
      font-size: 24px;
    }

    p {
      margin: 0 0 12px;
      line-height: 1.6;
      color: var(--text-muted);
      font-size: 15px;
    }

    .card {
      background: var(--gray-bg);
      border-radius: 16px;
      border: 1px solid var(--gray-border);
      padding: 20px 20px 22px;
    }

    /* Intro section: card with text on left, image space on right */
    .intro-card {
      display: grid;
      grid-template-columns: minmax(0, 3fr) minmax(0, 2fr);
      gap: 18px;
      align-items: start;
      margin-bottom: 20px;
    }

    .intro-card .intro-text {
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .intro-card .intro-image {
      border-radius: 12px;
      border: 1px dashed #d1d5db;
      background: linear-gradient(135deg, #f9fafb, #e5e7eb);
      min-height: 140px;
      font-size: 13px;
      color: var(--text-muted);
      display: flex;
      align-items: center;
      justify-content: center;
      text-align: center;
      padding: 12px;
    }

    /* Stack text and image on small screens */
    @media (max-width: 800px) {
      .intro-card {
        grid-template-columns: 1fr;
      }
    }


    .two-column {
      display: grid;
      grid-template-columns: minmax(0, 3fr) minmax(0, 2fr);
      gap: 24px;
    }

    @media (max-width: 800px) {
      .two-column {
        grid-template-columns: 1fr;
      }
    }

    /* Hero section */
    .hero {
      min-height: 80vh;
      display: flex;
      align-items: center;
      justify-content: center;
      padding-top: 80px;
    }

    .hero-title {
      font-size: clamp(40px, 7vw, 60px);
    }

    .hero-tagline {
      font-size: 15px;
      max-width: 480px;
      color: var(--text-muted);
      margin-top: 12px;
    }

    .hero-meta {
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      margin-top: 20px;
      font-size: 12px;
      color: var(--text-muted);
    }

    .pill {
      padding: 4px 10px;
      border-radius: 999px;
      border: 1px solid var(--gray-border);
      background: #ffffff;
    }

    /* Scroll arrow */
    .scroll-indicator {
      margin-top: 32px;
      display: inline-flex;
      flex-direction: column;
      align-items: center;
      gap: 4px;
      font-size: 11px;
      color: var(--text-muted);
      cursor: pointer;
    }

    .arrow-down {
      font-size: 18px;
      animation: bounce 1.5s infinite;
    }

    @keyframes bounce {
      0%, 100% { transform: translateY(0); }
      50% { transform: translateY(6px); }
    }

    /* Simple “image” placeholders as gray blocks (you can swap with real images later) */
    .image-placeholder {
      width: 100%;
      min-height: 180px;
      border-radius: 16px;
      background: linear-gradient(135deg, #f3f4f6, #e5e7eb);
      border: 1px dashed #d1d5db;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 13px;
      color: var(--text-muted);
      text-align: center;
      padding: 16px;
    }

    ul {
      padding-left: 18px;
      margin: 0 0 12px;
      color: var(--text-muted);
      font-size: 15px;
    }

    li {
      margin-bottom: 6px;
    }

    footer {
      padding: 24px 20px 40px;
      text-align: center;
      font-size: 11px;
      color: var(--text-muted);
      border-top: 1px solid #f3f4f6;
    }
  </style>
</head>
<body>

  <!-- Fixed header -->
  <header>
    <div class="logo">♻️ EcoSort</div>
    <nav>
      <a href="#introduction">Introduction</a>
      <a href="#data-prep">Data &amp; Prep</a>
      <a href="#analysis">Analysis</a>
      <a href="#results">Results</a>
      <a href="#conclusion">Conclusion</a>
      <a href="#about">About</a>
    </nav>
  </header>

  <main>

    <!-- Hero -->
    <section class="hero" id="top">
      <div class="section-inner">
        <h1 class="hero-title">EcoSort</h1>
        <p class="hero-tagline">
          An AI-assisted waste classification project that explores how simple images of everyday trash
          can support better recycling, less contamination, and more sustainable cities.
        </p>

        <div class="hero-meta">
          <div class="pill">CNN &amp; Image Classification</div>
          <div class="pill">TrashNet Dataset</div>
          <div class="pill">Recycling &amp; Sustainability</div>
        </div>

        <a href="#introduction" class="scroll-indicator">
          <span>Scroll to begin</span>
          <span class="arrow-down">↓</span>
        </a>
      </div>
    </section>

    <!-- Introduction -->
    <section id="introduction">
    <div class="section-inner">
      <div class="section-label">Section 1 · Introduction</div>
      <h2>Understanding everyday waste decisions</h2>

      <!-- 1. Clearly describe the topic -->
      <div class="card intro-card">
        <div class="intro-text">
          <h3>What is EcoSort about?</h3>
          <p>
            EcoSort focuses on a very ordinary moment that most people rarely think about:
            the second when they stand in front of a set of bins and decide where to throw
            something away. In that moment, a bottle, cup, or takeout container is 
            assigned to a path that either keeps it in circulation or sends it straight to a
            landfill. The topic of this project is not about technology first, but about these
            daily choices and the streams of material they create. By paying close attention
            to how items are sorted, we can better understand how much potential value is
            casually discarded. EcoSort uses images of everyday trash as a way to look more
            carefully at these decisions and the patterns hidden inside them.
          </p>
        </div>
        <div class="intro-image">
          Space for an image of a person standing in front of multiple bins
          (recycling, landfill, compost) trying to decide where to throw an item.
        </div>
      </div>

      <!-- 2. Topic background -->
      <div class="card intro-card">
        <div class="intro-text">
          <h3>Background: how waste systems work</h3>
          <p>
            Modern cities, campuses, and neighborhoods rely on long, complex waste systems
            that begin at a bin and stretch through trucks, sorting centers, and processing
            facilities. Once materials leave our hands, they pass through conveyor belts,
            workers, and machines that try to separate what can be reused from what must be
            buried or burned. These systems function best when items arrive in the right
            stream, such as clean glass in glass containers and cardboard in paper recycling.
            When the wrong items appear in the wrong place, the quality of the whole batch
            can drop. Understanding this background helps explain why small sorting mistakes
            at the bin can echo throughout the rest of the system.
          </p>
        </div>
        <div class="intro-image">
          Space for a diagram or photo showing the journey of waste:
          bin → truck → sorting facility → recycling or landfill.
        </div>
      </div>

      <!-- 3. Who is affected -->
      <div class="card intro-card">
        <div class="intro-text">
          <h3>Who is affected by mis-sorted waste?</h3>
          <p>
            When waste is mis-sorted, the impact is shared by many different groups of
            people. Residents and students may feel that they are doing the right thing by
            placing items in a recycling bin, only to learn later that contamination caused
            the entire load to be discarded. Workers at sorting facilities face additional
            effort and potential safety risks when they have to pull out items that never
            should have entered a particular stream. Local governments and building managers
            may pay higher fees when loads are rejected or when special handling is required.
            Over time, these combined effects influence taxpayers, rate-payers, and community
            members who depend on affordable and reliable waste services.
          </p>
        </div>
        <div class="intro-image">
          Space for an image showing different people affected:
          residents, facility workers, city staff, and community members.
        </div>
      </div>

      <!-- 4. Significance and applications -->
      <div class="card intro-card">
        <div class="intro-text">
          <h3>Why does better sorting matter?</h3>
          <p>
            Better waste sorting matters because it directly shapes how many materials stay
            in use and how many end up as permanent waste. When recyclable items are kept
            clean and separated, they can be turned into new products, reducing the need to
            extract fresh raw materials such as timber, metals, and fossil fuels. This can
            lower energy use, cut emissions, and decrease the environmental damage tied to
            mining and manufacturing. Well-sorted waste streams also make it easier for
            cities and organizations to meet their sustainability goals. In everyday terms,
            clearer sorting means fewer overflowing bins, cleaner shared spaces, and systems
            that feel trustworthy rather than confusing.
          </p>
        </div>
        <div class="intro-image">
          Space for an image comparing outcomes:
          clean recyclables becoming new products versus mixed waste going to landfill.
        </div>
      </div>

      <!-- 5. How images connect to the topic (still non-technical) -->
      <div class="card intro-card">
        <div class="intro-text">
          <h3>Where do images fit into this story?</h3>
          <p>
            Pictures of trash may seem unremarkable at first, but they offer a clear window
            into the kinds of objects that move through our bins every day. A single photo
            can show details such as shape, color, material, labels, and signs of damage or
            contamination that influence how people decide where an item belongs. By
            collecting many images of everyday waste, we can begin to see patterns in what
            people throw away and how similar different items appear to the human eye.
            These visual patterns hint at how tools, signs, or digital aids might someday
            support better decisions at the bin. EcoSort treats images as a gentle, visual
            starting point for thinking more carefully about waste, not as a replacement
            for education or policy.
          </p>
        </div>
        <div class="intro-image">
          Space for a collage of item photos:
          bottles, cups, boxes, cans, and mixed trash on neutral backgrounds.
        </div>
      </div>

    </div>
  </section>



    <!-- Data & Preparation -->
    <section id="data-prep">
      <div class="section-inner">
        <div class="section-label">Section 2 · Data &amp; Preparation</div>
        <div class="two-column">
          <div>
            <h2>Images of everyday waste</h2>
            <div class="card">
              <p>
                EcoSort uses a public image collection known as the TrashNet dataset. The dataset contains
                photographs of common waste items placed on a simple background, grouped into six categories:
                cardboard, glass, metal, paper, plastic, and mixed trash. Each image represents a single item,
                such as a cardboard box, a plastic bottle, or a crushed can. These labeled examples form the
                starting point for teaching a model how different types of materials tend to look.
              </p>
              <p>
                Before any modeling can happen, the images need to be organized and cleaned. In this project,
                all photographs are resized to a consistent shape so that they can be processed in the same way.
                The dataset is then divided into three parts: a training set that the model learns from, a
                validation set used to tune the model, and a test set reserved for final evaluation. Simple
                visual checks help confirm that the categories are balanced and that the images are clear,
                recognizable, and aligned with their labels. Links to the raw and processed data are provided
                so that others can reproduce these steps.
              </p>
            </div>
          </div>
          <div>
            <div class="image-placeholder">
              Possible visual: small grid of example images for each class
              (cardboard, glass, metal, paper, plastic, trash) with labels.
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Analysis -->
    <section id="analysis">
      <div class="section-inner">
        <div class="section-label">Section 3 · Analysis · Models &amp; Methods</div>
        <div class="two-column">
          <div>
            <h2>Teaching a model to “see” materials</h2>
            <div class="card">
              <p>
                At the heart of EcoSort is a type of model that is commonly used for images: a Convolutional
                Neural Network (CNN). Rather than working with raw text or numbers alone, a CNN is designed
                to look at pixel patterns and gradually build up an understanding of shapes, edges, and textures.
                With enough examples, the model can begin to recognize that crumpled paper tends to look
                different from transparent plastic, and that glass bottles reflect light in a distinctive way.
              </p>
              <p>
                For this project, the CNN is trained to take a single waste image as input and assign it to
                one of the six categories. The training process adjusts the internal parameters of the model
                so that its predictions align more closely with the labeled examples over time. Alongside the
                core model, additional tools such as Grad-CAM visualizations are used to highlight which parts
                of the image the network is focusing on when it makes a decision. This helps connect the
                technical behavior of the model back to something humans can interpret and reason about.
              </p>
            </div>
          </div>
          <div>
            <div class="image-placeholder">
              Possible visual: a simplified block diagram of the CNN,
              from input image → feature extraction → classification layer,
              with arrows showing the flow.
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Results -->
    <section id="results">
      <div class="section-inner">
        <div class="section-label">Section 4 · Results</div>
        <div class="two-column">
          <div>
            <h2>How well does EcoSort perform?</h2>
            <div class="card">
              <p>
                After training, EcoSort is evaluated on a set of images it has never seen before. For each
                photograph, the model is asked to predict the correct category, and its answers are compared
                against the true labels. The overall accuracy gives a single summary of how often EcoSort is
                correct, but a more detailed view comes from a confusion matrix, which shows which categories
                are most frequently mistaken for one another.
              </p>
              <p>
                In practice, the model performs strongly on clearly separated materials such as glass and
                cardboard, while showing more uncertainty when items are partially damaged, crumpled, or
                visually similar across categories. These patterns mirror the real-world challenges of
                recycling, where a slightly contaminated item can easily be misidentified. Example predictions
                and heatmaps from Grad-CAM provide concrete illustrations of when EcoSort is confident, when
                it hesitates, and where it directs its attention within each image.
              </p>
            </div>
          </div>
          <div>
            <div class="image-placeholder">
              Insert here: test-set confusion matrix image and a few
              side-by-side panels of input image, predicted label,
              and Grad-CAM heatmap.
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Conclusion -->
    <section id="conclusion">
      <div class="section-inner">
        <div class="section-label">Section 5 · Conclusion</div>
        <div class="card">
          <h2>From images to more mindful waste systems</h2>
          <p>
            EcoSort does not claim to solve recycling, but it shows that even a relatively simple image-based
            model can reliably recognize common materials and highlight where confusion tends to arise. The
            project suggests that automated classification could act as a quiet assistant in the background:
            guiding smart bins, supporting staff at sorting facilities, or providing feedback in educational
            settings where people are still learning what goes where. By surfacing which items are consistently
            mis-sorted, such systems can also inform better signage, clearer instructions, and more thoughtful
            design of collection points.
          </p>
          <p>
            More broadly, this work is an example of how neural networks can be pointed at everyday sustainability
            problems rather than only abstract benchmarks. Turning a single photo into a category label is a small
            step, but it opens a path toward waste streams that are cleaner, less contaminated, and easier to
            process. EcoSort invites future extensions: adding compostable materials, handling mixed scenes with
            multiple items, or moving from controlled backgrounds to real-world environments like campuses,
            offices, and city streets. Each of these steps could make automated support for sorting feel less like
            a futuristic idea and more like a practical tool for reducing waste.
          </p>
        </div>
      </div>
    </section>

    <!-- About -->
    <section id="about">
      <div class="section-inner">
        <div class="section-label">Section 6 · About</div>
        <div class="card">
          <h2>About the project</h2>
          <p>
            EcoSort was developed as a neural networks course project exploring how computer vision can support
            sustainability-focused applications. The work combines publicly available data, reproducible code,
            and transparent evaluation so that others can build on the ideas, question the limitations, and
            imagine new ways to connect machine learning with everyday environmental decisions.
          </p>
          <p>
            All datasets, code, and trained models used in this project are linked through the accompanying
            GitHub repository. The intention is that any interested student, practitioner, or educator can
            re-run the experiments, adapt the model to new settings, or use the visuals as part of broader
            conversations about waste, recycling, and responsible technology.
          </p>
        </div>
      </div>
    </section>

  </main>

  <footer>
    EcoSort · AI-assisted waste classification for cleaner, smarter recycling.
  </footer>

</body>
</html>
