<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>EcoSort – AI-Powered Waste Classification</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <style>
    :root {
      --green-main: #166534;       /* deep calm green */
      --green-soft: #15803d;
      --gray-bg:   #f5f5f5;       /* light gray cards */
      --gray-border: #e5e5e5;
      --text-muted: #4b5563;
      --max-width: 900px;
    }

    * {
      box-sizing: border-box;
      scroll-behavior: smooth;
    }

    body {
      margin: 0;
      padding: 0;
      font-family: -apple-system, BlinkMacSystemFont, "SF Pro Text",
                   system-ui, -system-ui, "Segoe UI", sans-serif;
      background: #ffffff;
      color: var(--green-main);
    }

    a {
      color: inherit;
      text-decoration: none;
    }

    /* Top nav – minimal, low visual weight */
    header {
      position: fixed;
      top: 0;
      left: 0;
      right: 0;
      height: 56px;
      background: rgba(255, 255, 255, 0.9);
      backdrop-filter: blur(10px);
      border-bottom: 1px solid rgba(229, 231, 235, 0.8);
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 0 24px;
      z-index: 20;
    }

    .logo {
      font-weight: 600;
      letter-spacing: 0.04em;
      font-size: 14px;
      text-transform: uppercase;
    }

    nav {
      display: flex;
      gap: 18px;
      font-size: 13px;
    }

    nav a {
      padding: 4px 8px;
      border-radius: 999px;
      color: var(--text-muted);
    }

    nav a:hover {
      background: #f3f4f6;
      color: var(--green-main);
    }

    /* Layout for sections */
    main {
      padding-top: 72px; /* space for fixed header */
    }

    section {
      min-height: 70vh;
      padding: 40px 20px 60px;
      display: flex;
      justify-content: center;
    }

    .section-inner {
      width: 100%;
      max-width: var(--max-width);
    }

    .section-label {
      font-size: 11px;
      letter-spacing: 0.16em;
      text-transform: uppercase;
      color: var(--text-muted);
      margin-bottom: 8px;
    }

    h1, h2 {
      margin: 0 0 16px;
      font-weight: 600;
      letter-spacing: 0.02em;
    }

    h1 {
      font-size: clamp(32px, 5vw, 48px);
    }

    h2 {
      font-size: 24px;
    }

    p {
      margin: 0 0 12px;
      line-height: 1.6;
      color: var(--text-muted);
      font-size: 15px;
    }

    .card {
      background: var(--gray-bg);
      border-radius: 16px;
      border: 1px solid var(--gray-border);
      padding: 20px 20px 22px;
    }

    .two-column {
      display: grid;
      grid-template-columns: minmax(0, 3fr) minmax(0, 2fr);
      gap: 24px;
    }

    @media (max-width: 800px) {
      .two-column {
        grid-template-columns: 1fr;
      }
    }

    /* Hero section */
    .hero {
      min-height: 80vh;
      display: flex;
      align-items: center;
      justify-content: center;
      padding-top: 80px;
    }

    .hero-title {
      font-size: clamp(40px, 7vw, 60px);
    }

    .hero-tagline {
      font-size: 15px;
      max-width: 480px;
      color: var(--text-muted);
      margin-top: 12px;
    }

    .hero-meta {
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      margin-top: 20px;
      font-size: 12px;
      color: var(--text-muted);
    }

    .pill {
      padding: 4px 10px;
      border-radius: 999px;
      border: 1px solid var(--gray-border);
      background: #ffffff;
    }

    /* Scroll arrow */
    .scroll-indicator {
      margin-top: 32px;
      display: inline-flex;
      flex-direction: column;
      align-items: center;
      gap: 4px;
      font-size: 11px;
      color: var(--text-muted);
      cursor: pointer;
    }

    .arrow-down {
      font-size: 18px;
      animation: bounce 1.5s infinite;
    }

    @keyframes bounce {
      0%, 100% { transform: translateY(0); }
      50% { transform: translateY(6px); }
    }

    /* Simple “image” placeholders as gray blocks (you can swap with real images later) */
    .image-placeholder {
      width: 100%;
      min-height: 180px;
      border-radius: 16px;
      background: linear-gradient(135deg, #f3f4f6, #e5e7eb);
      border: 1px dashed #d1d5db;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 13px;
      color: var(--text-muted);
      text-align: center;
      padding: 16px;
    }

    ul {
      padding-left: 18px;
      margin: 0 0 12px;
      color: var(--text-muted);
      font-size: 15px;
    }

    li {
      margin-bottom: 6px;
    }

    footer {
      padding: 24px 20px 40px;
      text-align: center;
      font-size: 11px;
      color: var(--text-muted);
      border-top: 1px solid #f3f4f6;
    }
  </style>
</head>
<body>

  <!-- Fixed header -->
  <header>
    <div class="logo">EcoSort</div>
    <nav>
      <a href="#introduction">Introduction</a>
      <a href="#data-prep">Data &amp; Prep</a>
      <a href="#analysis">Analysis</a>
      <a href="#results">Results</a>
      <a href="#conclusion">Conclusion</a>
      <a href="#about">About</a>
    </nav>
  </header>

  <main>

    <!-- Hero -->
    <section class="hero" id="top">
      <div class="section-inner">
        <div class="section-label">Neural Networks · Sustainability · Computer Vision</div>
        <h1 class="hero-title">EcoSort</h1>
        <p class="hero-tagline">
          An AI-assisted waste classification project that explores how simple images of everyday trash
          can support better recycling, less contamination, and more sustainable cities.
        </p>

        <div class="hero-meta">
          <div class="pill">CNN · Image Classification</div>
          <div class="pill">TrashNet Dataset</div>
          <div class="pill">Recycling &amp; Sustainability</div>
        </div>

        <a href="#introduction" class="scroll-indicator">
          <span>Scroll to begin</span>
          <span class="arrow-down">↓</span>
        </a>
      </div>
    </section>

    <!-- Introduction -->
    <section id="introduction">
      <div class="section-inner">
        <div class="section-label">Section 1 · Introduction</div>
        <div class="two-column">
          <div>
            <h2>Why waste sorting matters</h2>
            <div class="card">
              <p>
                EcoSort focuses on a simple but powerful idea: where our trash goes is rarely an accident.
                When recyclable items are thrown into the wrong bin, entire loads of material can be
                contaminated and sent directly to landfills or incinerators instead of being recovered.
                This mis-sorting happens every day in homes, offices, and public spaces, and the impact
                quietly adds up over time. Materials that could have been turned into new paper, glass,
                or plastic products are instead lost, while new resources are extracted to replace them.
              </p>
              <p>
                The goal of this project is not to “perfect” recycling, but to understand how simple,
                image-based tools might help people and systems make better sorting decisions. In this
                work, images of everyday items such as bottles, cans, cardboard, and mixed trash are used
                as inputs to a model that attempts to recognize the category of each object. The broader
                question is human-centered: if we can teach a computer to distinguish common waste types
                from a photo, how might that assist communities, campuses, or facilities that are trying
                to reduce contamination and send less material to landfills?
              </p>
            </div>
          </div>

          <div>
            <div class="image-placeholder">
              Illustrative idea: a simple diagram of three bins (recycling, compost, landfill)
              with common items above each bin, showing how mis-sorting pushes recyclables into
              the wrong stream.
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Data & Preparation -->
    <section id="data-prep">
      <div class="section-inner">
        <div class="section-label">Section 2 · Data &amp; Preparation</div>
        <div class="two-column">
          <div>
            <h2>Images of everyday waste</h2>
            <div class="card">
              <p>
                EcoSort uses a public image collection known as the TrashNet dataset. The dataset contains
                photographs of common waste items placed on a simple background, grouped into six categories:
                cardboard, glass, metal, paper, plastic, and mixed trash. Each image represents a single item,
                such as a cardboard box, a plastic bottle, or a crushed can. These labeled examples form the
                starting point for teaching a model how different types of materials tend to look.
              </p>
              <p>
                Before any modeling can happen, the images need to be organized and cleaned. In this project,
                all photographs are resized to a consistent shape so that they can be processed in the same way.
                The dataset is then divided into three parts: a training set that the model learns from, a
                validation set used to tune the model, and a test set reserved for final evaluation. Simple
                visual checks help confirm that the categories are balanced and that the images are clear,
                recognizable, and aligned with their labels. Links to the raw and processed data are provided
                so that others can reproduce these steps.
              </p>
            </div>
          </div>
          <div>
            <div class="image-placeholder">
              Possible visual: small grid of example images for each class
              (cardboard, glass, metal, paper, plastic, trash) with labels.
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Analysis -->
    <section id="analysis">
      <div class="section-inner">
        <div class="section-label">Section 3 · Analysis · Models &amp; Methods</div>
        <div class="two-column">
          <div>
            <h2>Teaching a model to “see” materials</h2>
            <div class="card">
              <p>
                At the heart of EcoSort is a type of model that is commonly used for images: a Convolutional
                Neural Network (CNN). Rather than working with raw text or numbers alone, a CNN is designed
                to look at pixel patterns and gradually build up an understanding of shapes, edges, and textures.
                With enough examples, the model can begin to recognize that crumpled paper tends to look
                different from transparent plastic, and that glass bottles reflect light in a distinctive way.
              </p>
              <p>
                For this project, the CNN is trained to take a single waste image as input and assign it to
                one of the six categories. The training process adjusts the internal parameters of the model
                so that its predictions align more closely with the labeled examples over time. Alongside the
                core model, additional tools such as Grad-CAM visualizations are used to highlight which parts
                of the image the network is focusing on when it makes a decision. This helps connect the
                technical behavior of the model back to something humans can interpret and reason about.
              </p>
            </div>
          </div>
          <div>
            <div class="image-placeholder">
              Possible visual: a simplified block diagram of the CNN,
              from input image → feature extraction → classification layer,
              with arrows showing the flow.
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Results -->
    <section id="results">
      <div class="section-inner">
        <div class="section-label">Section 4 · Results</div>
        <div class="two-column">
          <div>
            <h2>How well does EcoSort perform?</h2>
            <div class="card">
              <p>
                After training, EcoSort is evaluated on a set of images it has never seen before. For each
                photograph, the model is asked to predict the correct category, and its answers are compared
                against the true labels. The overall accuracy gives a single summary of how often EcoSort is
                correct, but a more detailed view comes from a confusion matrix, which shows which categories
                are most frequently mistaken for one another.
              </p>
              <p>
                In practice, the model performs strongly on clearly separated materials such as glass and
                cardboard, while showing more uncertainty when items are partially damaged, crumpled, or
                visually similar across categories. These patterns mirror the real-world challenges of
                recycling, where a slightly contaminated item can easily be misidentified. Example predictions
                and heatmaps from Grad-CAM provide concrete illustrations of when EcoSort is confident, when
                it hesitates, and where it directs its attention within each image.
              </p>
            </div>
          </div>
          <div>
            <div class="image-placeholder">
              Insert here: test-set confusion matrix image and a few
              side-by-side panels of input image, predicted label,
              and Grad-CAM heatmap.
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Conclusion -->
    <section id="conclusion">
      <div class="section-inner">
        <div class="section-label">Section 5 · Conclusion</div>
        <div class="card">
          <h2>From images to more mindful waste systems</h2>
          <p>
            EcoSort does not claim to solve recycling, but it shows that even a relatively simple image-based
            model can reliably recognize common materials and highlight where confusion tends to arise. The
            project suggests that automated classification could act as a quiet assistant in the background:
            guiding smart bins, supporting staff at sorting facilities, or providing feedback in educational
            settings where people are still learning what goes where. By surfacing which items are consistently
            mis-sorted, such systems can also inform better signage, clearer instructions, and more thoughtful
            design of collection points.
          </p>
          <p>
            More broadly, this work is an example of how neural networks can be pointed at everyday sustainability
            problems rather than only abstract benchmarks. Turning a single photo into a category label is a small
            step, but it opens a path toward waste streams that are cleaner, less contaminated, and easier to
            process. EcoSort invites future extensions: adding compostable materials, handling mixed scenes with
            multiple items, or moving from controlled backgrounds to real-world environments like campuses,
            offices, and city streets. Each of these steps could make automated support for sorting feel less like
            a futuristic idea and more like a practical tool for reducing waste.
          </p>
        </div>
      </div>
    </section>

    <!-- About -->
    <section id="about">
      <div class="section-inner">
        <div class="section-label">Section 6 · About</div>
        <div class="card">
          <h2>About the project</h2>
          <p>
            EcoSort was developed as a neural networks course project exploring how computer vision can support
            sustainability-focused applications. The work combines publicly available data, reproducible code,
            and transparent evaluation so that others can build on the ideas, question the limitations, and
            imagine new ways to connect machine learning with everyday environmental decisions.
          </p>
          <p>
            All datasets, code, and trained models used in this project are linked through the accompanying
            GitHub repository. The intention is that any interested student, practitioner, or educator can
            re-run the experiments, adapt the model to new settings, or use the visuals as part of broader
            conversations about waste, recycling, and responsible technology.
          </p>
        </div>
      </div>
    </section>

  </main>

  <footer>
    EcoSort · AI-assisted waste classification for cleaner, smarter recycling.
  </footer>

</body>
</html>
